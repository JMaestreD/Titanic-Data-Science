---
title: "Pruebas y recursos sobre kaggle Titanic "
author: "Javier Maestre Deusto y Miguel López Marzabal"
date: '`r format(Sys.Date(),"%e de %B, %Y")`'
output:
  pdf_document: 
    toc: yes
    toc_depth: 3
  html_document:
    df_print: paged
editor_options: 
  chunk_output_type: console
---

\newpage

# Configuración, carga de librerías y definición de funciones.

Realizamos la carga de las librerías necesarias
```{r load_libraries, echo = TRUE}
location_library <- NULL
location_library2 <- NULL
if(Sys.info()[[4]]!="ASUS-WIN10-X64") {
  location_library <- "/usr/local/lib/R/site-library"
  location_library2 <- "/usr/lib/R/library"
}
library(knitr)
library(kableExtra)
#library(faraway)
library(tinytex, lib.loc = "/usr/local/lib/R/site-library")
library(stringr, lib.loc = "/usr/local/lib/R/site-library")
#library(hms, lib.loc = "/usr/local/lib/R/site-library")
library(ggplot2, lib.loc = "/usr/local/lib/R/site-library")
library(tinytex, lib.loc = location_library)
library(stringr, lib.loc = location_library)
#library(hms, lib.loc = location_library)
library(ggplot2, lib.loc = location_library)
#library(ggpubr)
library(car)
library(corrplot) #para los gráficos de correlaciones
library(InformationValue)
#library(cowplot)
<<<<<<< HEAD
library(ResourceSelection)
library(lmtest, lib.loc = "/usr/local/lib/R/site-library")
library(DAAG)
library(caret)
=======
#library(ResourceSelection)
#library(lmtest, lib.loc = location_library)
#library(DAAG)
#library(caret)
>>>>>>> 8719e06c071e5ccf5020a752c7cbe8f9b23babd8
#library(readr)
library(rpart, lib.loc = location_library2)
library(VIM, quietly = TRUE)
library(randomForest)
library(party)
library(dplyr)
library(FactoMineR)
library(factoextra)
library(survival, lib.loc = "/usr/lib/R/library")
library(psych)
library(MASS, lib.loc = "/usr/lib/R/library")
library(mlr)
library(mlbench)
```
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

## Bajar tamaño fuente del chunk al generar pdf
## (https://stackoverflow.com/questions/25646333/code-chunk-font-size-in-rmarkdown-with-knitr-and-latex)
def.chunk.hook  <- knitr::knit_hooks$get("chunk")
knitr::knit_hooks$set(chunk = function(x, options) {
  x <- def.chunk.hook(x, options)
  ifelse(options$size != "normalsize", paste0("\n \\", options$size,"\n\n", x, "\n\n \\normalsize"), x)
})
```  
# Lectura y carga de datos de los ficheros
```{r lectura_fichero, size="small"}
#leemos el fichero train
train <- read.csv("titanic/train.csv")
#leemos el fichero test
test <- read.csv("titanic/test.csv")
#mostramos la estructura del dataset para ver tipos de variables
str(train)
#mostramos un resumen numérico de las variables del dataset
summary(train)
```
# Pruebas con los datos de origen
```{r pruebas_mrzs, size="small"}

#juntamos train + test añadiendo a test el campo Survived a Na
#vamos a trabajar con todos los datos para analizar mejor las variables, corregir y limpiar cualquier cosa 
muestra<-rbind(train,cbind(test, Survived = rep(NA,418)))
```

# Trabajo con las diferentes variables
En este documento vamos a separar el trabajo hecho en cada variable, por tanto irán mezcladas cosas de preprocesado 

## Trabajo con Ticket

```{r pruebas_mrzs_Ticket, size="small"}
#TRABAJO CON TICKET
muestra$TktNum <- NA
# Partimos ticket para obtener el prefijo(o Na si no hay)
muestra[,c('TktPre','TktNum')] <- str_match(muestra$Ticket, '(.* )?([0-9]+)' ) [,-1]

#vamos a ver relaciones del numero de ticket por tamaño
tamanoticket<-str_length(muestra$TktNum)
# hay 4 elementos con NA que tienen ticket LINE y solo ha sobrevivido 1, los ponemos a tamño 0
tamanoticket[is.na(tamanoticket)]<-0
#vemos las probabilidades de supervivencia según tamanoticket
aggregate(Survived ~ tamanoticket, data=muestra, FUN=function(x) {sum(x)/length(x)})
#vemos cuantos elementos hay en cada uno de los tamaños
table(tamanoticket)
# AÑADIR A DATASET luego veremos si vale o no
muestra$tamanoticket<-tamanoticket
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$tamanoticket),length)
names(countsClassVar) <- c("Survived","Tamanos","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=Tamanos)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función de la longitud del ticket number") +
  xlab("Longitud numero ticket") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))

#quitamos los signos de puntuacion y caracteres raros de TktPre
muestra$TktPre <- str_replace_all(str_to_upper(muestra$TktPre), '[.]', '') 
muestra$TktPre <- str_replace_all(str_to_upper(muestra$TktPre), '[/]', '') 
muestra$TktPre <- str_replace_all(str_to_upper(muestra$TktPre), ' ', '') 
#corregimos algunos casos aislados que parecen mal escritos
muestra$TktPre[muestra$TktPre=='AS']<-'A5'
#vemos proporcion de supervivencia de los grupos
aggregate(Survived ~ TktPre, data=muestra, FUN=function(x) {sum(x)/length(x)})
#mostramos el numero de elementos de cada grupo
auxtbl<-table(muestra$TktPre)
auxtbl[order(auxtbl)]
#ESTUDIAR SI ES INTERESANTE Y AÑADIR A DATASET
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$TktPre),length)
names(countsClassVar) <- c("Survived","TktPre","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=TktPre)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del prefijo del ticket") +
  xlab("Prefijo Ticket") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))


#cuando varias personas viajan juntas puede que compartan ticket
tableTickets <- table(muestra$TktNum)
TicketFreq <- as.numeric(tableTickets[as.character(muestra$TktNum)])
#Nos vale para ver que personas viajaban solas sin amigos ni familiares
#mostramos frecuencia de los datos
table(TicketFreq)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ TicketFreq, FUN=function(x) {sum(x)/length(x)})
muestra$TicketFreq<-TicketFreq
#Limpieza porque hay algunos tickets LINE que no tienen numero (Se podrían limpiar antes de extraer la frecuencia pero)
muestra[is.na(muestra$TicketFreq),]
muestra$TicketFreq[is.na(muestra$TicketFreq)]<-1
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$TicketFreq),length)
names(countsClassVar) <- c("Survived","TicketFreq","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=TicketFreq)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función de la cantidad de tickets iguales") +
  xlab("Numero tickets iguales") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))

#-----------------------------------------------------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------------------------------------------------

```

## Trabajo con Name

```{r pruebas_mrzs_Name, size="small"}
#TRABAJO CON NAME
Nombres <- as.character(muestra$Name)
#Partimos por la coma
ApellidoYResto<-str_split(Nombres,',',simplify=TRUE)
#Nos quedamos con el apellido, no hace falta eliminar espacios
Apellido<-ApellidoYResto[,1]
#mostramos frecuencia de los datos
#table(Apellido)
#vemos proporcion de supervivencia de los grupos
#aggregate(muestra$Survived ~ Apellido, FUN=function(x) {sum(x)/length(x)})



#partimos por el punto y nos quedamos con el título
Titulo<-str_split(ApellidoYResto[,2],'\\.',simplify=TRUE)[,1]
#eliminamos el espacio anterior
Titulo <- sub(' ', '', Titulo)
#mostramos frecuencia de los datos
table(Titulo)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ Titulo, FUN=function(x) {sum(x)/length(x)})
#Vamos a combinar los titulos poco frecuentes en relación a su porcentaje de supervivencia 
Titulo[Titulo %in% c('Col', 'Major')] <- 'titulogrupo05'
Titulo[Titulo %in% c('Dona', 'Lady', 'the Countess', 'Mlle', 'Mme', 'Ms', 'Sir')] <- 'titulogrupo1'
Titulo[Titulo %in% c('Jonkheer', 'Don', 'Capt', 'Rev')] <- 'titulogrupo0'
# Convert to a factor
Titulo <- as.factor(Titulo)
#mostramos frecuencia de los datos
table(Titulo)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ Titulo, FUN=function(x) {sum(x)/length(x)})
muestra$Titulo<-Titulo
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$Titulo),length)
names(countsClassVar) <- c("Survived","Titulo","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=Titulo)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del titulo de la persona") +
  xlab("Titulo") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))



#CONSTRUCCION DE FAMILIAS DE PASAJEROS
#vemos el tamaño de familia de cada individuo
FamSize <- muestra$SibSp+muestra$Parch + 1
#mostramos frecuencia de los datos
table(FamSize)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ FamSize, FUN=function(x) {sum(x)/length(x)})
#parece que hay familias incompletas de 7,6,5,4 miembros!!!!PENSAR COMO RESOLVER ESTO
muestra$FamSize<-FamSize
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$FamSize),length)
names(countsClassVar) <- c("Survived","FamSize","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=FamSize)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del tamaño de la familia") +
  xlab("Número miembros de la familia") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))



#PASAJEROS QUE VIAJAN SOLOS
#el tamaño de familia solo nos indica si tiene familia, con esto sabemos si tampoco viajaba con amigos o amante o algo así. 
LoneWolfs <- FamSize == 1 & TicketFreq==1 
#mostramos frecuencia de los datos
table(LoneWolfs)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ LoneWolfs, FUN=function(x) {sum(x)/length(x)})
#añadimos al dataset
muestra$LoneWolfs<-LoneWolfs
#Hay 4 Nas que hay que corregir, viene de Ticket
muestra[is.na(muestra$LoneWolfs),]
muestra[is.na(muestra$LoneWolfs),]$TktNum <- 'LINE'
muestra[is.na(muestra$LoneWolfs),]$TktPre <- 'LINE'
muestra[is.na(muestra$LoneWolfs),]$LoneWolfs <- TRUE
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$LoneWolfs),length)
names(countsClassVar) <- c("Survived","LoneWolfs","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=LoneWolfs)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función de si viajan solos") +
  xlab("Viaja solo") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))





# concatenamos el apellido con el numero de familiares SE AGRUPAN MAL, HAY QUE UNIR NUMERO DE TICKET
FamilyID <- paste(as.character(FamSize), Apellido, sep="")
#mostramos frecuencia de los datos
#table(FamilyID)
#vemos proporcion de supervivencia de los grupos
#aggregate(muestra$Survived ~ FamilyID, FUN=function(x) {sum(x)/length(x)})
#agrupamos las familias pequeñas
FamilyIDGrouped<-FamilyID
FamilyIDGrouped[FamSize <= 2] <- 'Small'
#mostramos frecuencia de los datos
table(FamilyIDGrouped)
# agrupamos las familias que deberían tener 3 o más familiares pero en el recuento aparecen menos o igual que 2.
famIDs <- data.frame(table(FamilyIDGrouped))
famIDs <- famIDs[famIDs$Freq <= 2,]
FamilyIDGrouped[FamilyIDGrouped %in% famIDs$FamilyIDGrouped] <- 'Small'
#mostramos frecuencia de los datos
table(FamilyIDGrouped)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ FamilyIDGrouped, FUN=function(x) {sum(x)/length(x)})
#examinamos casos raros, parece que se están mezclando familias porque coincide apellido y numero de familiares
#igual es mejor usar los grupos de tickets
muestra[FamilyIDGrouped=='3Brown',] # Hay cuatro personas, por los tickets parece que se juntan dos familias
muestra[FamilyIDGrouped=='3Davies',] # Hay 5 personas, por los tickets parece que se juntan dos familias
muestra[FamilyIDGrouped=='7Andersson',] # hay 9, parece que se juntan la familia y dos personas diferentes por los tickets
# Convertimos a factor
FamilyIDGrouped <- factor(FamilyIDGrouped)



# probamos A UNIR NUMERO DE TICKET para obtener mejores grupos familiares
FamilyIDTK <- paste(as.character(FamSize), Apellido, muestra$TktNum, sep="")
#mostramos frecuencia de los datos
#table(FamilyIDTK)
#vemos proporcion de supervivencia de los grupos
#aggregate(muestra$Survived ~ FamilyIDTK, FUN=function(x) {sum(x)/length(x)})
#agrupamos las familias pequeñas
FamilyIDTKGrouped<-FamilyIDTK
FamilyIDTKGrouped[FamSize <= 2] <- 'Small'
#mostramos frecuencia de los datos
table(FamilyIDTKGrouped)
# agrupamos las familias que deberían tener 3 o más familiares pero en el recuento aparecen menos o igual que 2.
famIDs <- data.frame(table(FamilyIDTKGrouped))
famIDs <- famIDs[famIDs$Freq <= 2,]
FamilyIDTKGrouped[FamilyIDTKGrouped %in% famIDs$FamilyIDTKGrouped] <- 'Small'
#mostramos frecuencia de los datos
table(FamilyIDTKGrouped)
#vemos proporcion de supervivencia de las familias
aggregate(muestra$Survived ~ FamilyIDTKGrouped, FUN=function(x) {sum(x)/length(x)})
#vemos proporcion de supervivencia de los grupos por numero de miembros
numerodemiembrosgrupos<-as.numeric(table(FamilyIDTKGrouped)[as.character(FamilyIDTKGrouped)])
aggregate(muestra$Survived ~ numerodemiembrosgrupos, FUN=function(x) {sum(x)/length(x)})
# Convertimos a factor
FamilyIDTKGrouped <- factor(FamilyIDTKGrouped)



# probamos A UNIR NUMERO DE TICKET para obtener mejores grupos familiares Y AGRUPAMOS DE OTRA FORMA
FamilyIDTK <- sub(' ','_',paste(Apellido,as.character(FamSize), muestra$TktNum, sep="__"))
#mostramos frecuencia de los datos
#table(FamilyIDTK)
#vemos proporcion de supervivencia de los grupos
#aggregate(muestra$Survived ~ FamilyIDTK, FUN=function(x) {sum(x)/length(x)})
#agrupamos las familias pequeñas
FamilyIDTKGrouped<-FamilyIDTK
FamilyIDTKGrouped[FamSize <= 1] <- 'Alone'
#vemos cuantas parejas sobrevivieron a medias, todos o ninguno
coupleSurvRate<-aggregate(muestra$Survived[FamSize ==2] ~ FamilyIDTKGrouped[FamSize ==2], FUN=function(x) {sum(x)/length(x)})
table(as.factor(coupleSurvRate[,2]))
#ver si merece la pena usar el porcentaje de supervivencia familiar, hay varias teorías acerca de la supervivencia
#en funcion de cuantas personas de la familia hayan sobrevivido
#vamos a crear un porcentaje de supervivencia familiar que nos dice cuantos familiares sobreviven.
familySurvRate<-aggregate(muestra$Survived ~ FamilyIDTKGrouped, FUN=function(x) {sum(x)/length(x)})
familySurvRate
#acortamos más los grupos de edad
FamilyIDTKGrouped[FamSize == 2] <- 'Small'
#mostramos frecuencia de los datos
table(FamilyIDTKGrouped)
# agrupamos las familias que deberían tener 3 o más familiares pero en el recuento no aparecen.
famIDs <- data.frame(table(FamilyIDTKGrouped))
Alones <- famIDs[famIDs$Freq <= 1,]
FamilyIDTKGrouped[FamilyIDTKGrouped %in% Alones$FamilyIDTKGrouped] <- 'Alone'
Smalls <- famIDs[famIDs$Freq == 2,]
FamilyIDTKGrouped[FamilyIDTKGrouped %in% Smalls$FamilyIDTKGrouped] <- 'Small'
#mostramos frecuencia de los datos
table(FamilyIDTKGrouped)
#vemos proporcion de supervivencia de las familias
aggregate(muestra$Survived ~ FamilyIDTKGrouped, FUN=function(x) {sum(x)/length(x)})
#vemos proporcion de supervivencia de los grupos por numero de miembros
numerodemiembrosgrupos<-as.numeric(table(FamilyIDTKGrouped)[as.character(FamilyIDTKGrouped)])
aggregate(muestra$Survived ~ numerodemiembrosgrupos, FUN=function(x) {sum(x)/length(x)})
# Convertimos a factor
#FamilyIDTKGrouped <- factor(FamilyIDTKGrouped)
#añadimos al dataset
muestra$FamilyIDTKGrouped<-FamilyIDTKGrouped
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$FamilyIDTKGrouped),length)
names(countsClassVar) <- c("Survived","FamilyIDTKGrouped","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=FamilyIDTKGrouped)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función de su grupo familiar") +
  xlab("Grupo familiar") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))



#Juntamos el familyid con el numero de tickets juntos
familyticket<-as.data.frame(paste(FamilyID , TicketFreq))
familyticket<-paste(FamilyID , TicketFreq)
#mostramos frecuencia de los datos
#table(familyticket)
#vemos proporcion de supervivencia de los grupos
#aggregate(muestra$Survived ~ as.factor(familyticket), FUN=function(x) {sum(x)/length(x)})
#valdría para ver grupos heterogéneos de familia y amigos, pero no aporta nada, o eso creo.


#-----------------------------------------------------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------------------------------------------------

```

## Trabajo con Parch

```{r pruebas_mrzs_Parch, size="small"}

#TRABAJO CON Parch
#vamos a ver si las madres tuvieron más provabilidades de sobrevivir que las no madres
IsMother <- Titulo == "Mrs" & muestra$Parch > 0
#mostramos frecuencia de los datos
table(IsMother)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ IsMother, FUN=function(x) {sum(x)/length(x)})
#añadimos al dataset
muestra$IsMother<-IsMother
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$IsMother),length)
names(countsClassVar) <- c("Survived","IsMother","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=IsMother)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función de si es madre") +
  xlab("Es madre") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))


#-----------------------------------------------------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------------------------------------------------


```


## Trabajo con Embarqued

```{r pruebas_mrzs_Embarked, size="small"}
#TRABAJO CON Embarqued

#mostramos frecuencia de los datos
table(muestra$Embarked)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ muestra$Embarked, FUN=function(x) {sum(x)/length(x)})
# existen 2 elementos sin embarked o con el en blanco
#Limpieza
muestra[muestra$Embarked=='',]
#No encuentro nada que me pueda indicar el puerto de embarque así que ponemos S que es la más frecuente
muestra[muestra$Embarked=='',]$Embarked<-'S'
#reajustamos para que desaparezca el factor vacio
muestra$Embarked<-as.factor(as.character(muestra$Embarked))
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$Embarked),length)
names(countsClassVar) <- c("Survived","Embarked","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=Embarked)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del puerto de embarque") +
  xlab("Puerto") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))



#-----------------------------------------------------------------------------------------------------------------------------------------

```
## Trabajo con Cabina

```{r pruebas_mrzs_Cabina, size="small"}

#TRABAJO CON CABINA
#No merece la pena hay muchos perdidos

#Limpieza
#muestra[muestra$Cabin=='',]
#hay demasiados valores perdidos, no merece la pena 


#-----------------------------------------------------------------------------------------------------------------------------------------
```

## Trabajo con Fare

```{r pruebas_mrzs_Fare, size="small"}
#TRABAJO CON Fare

#Limpieza
#Valores perdidos
muestra[is.na(muestra$Fare),]
#rellenamos el valor perdido con el fare medio para su clase,su sexo y su numero de hijos, omitimos Nas.
muestra$Fare[is.na(muestra$Fare)] <- median(na.omit(muestra$Fare[muestra$Pclass==3 & muestra$Sex=="male" & muestra$Parch==0]))

#valores a 0
muestra[muestra$Fare==0,]
boxplot(muestra$Fare,
        data = muestra,
        ylab = "Fare del pasajero",
        main = "grafico de caja de Fare") 
boxplot.stats(muestra$Fare)$out 
#Parece que la variable está bastante afectada por los valores extremos, hay algun fare muy elevado.
boxplot(muestra[muestra$Fare!=0,]$Fare,
        data = muestra,
        ylab = "Fare del pasajero",
        main = "grafico de caja de Fare") 
boxplot.stats(muestra$Fare)$out 
#quitando los valores a 0 vemos que no varía nada los extremos superiores.
# tendríamos que ver que hacer con los outliers superiores
# podemos comprobar la Fare más alta de Test y el resto igual podemos no usarlo o agruparlo, dependiendo del porcentaje de supervivencia


# REALIZAMOS LA GENERACION DE CARACTERISTICAS DESPUES DE LIMPIAR PARA EVITAR Nas

#usamos la función cut para separar en grupos o categorías
FareGroups<-cut(muestra$Fare, 16, include.lowest=TRUE)
FareGroups<-as.character(FareGroups)
FareGroups[FareGroups %in% c("(288,320]","(320,352]","(352,384]","(384,416]","(416,448]","(448,480]","(480,513]")]<-  '290'  
FareGroups<-as.factor(FareGroups)
levels(FareGroups) <- paste("FG",as.character(as.integer(aggregate(muestra$Fare ~ FareGroups, FUN=function(x) {sum(x)/length(x)})$`muestra$Fare`)),sep='')
#mostramos frecuencia de los datos
table(FareGroups)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ FareGroups, FUN=function(x) {sum(x)/length(x)})
#vemos proporcion de supervivencia de los grupos y el sexo
aggregate(muestra$Survived ~ FareGroups+muestra$Sex, FUN=function(x) {sum(x)/length(x)})
table(FareGroups[muestra$Sex=='female'])
table(FareGroups[muestra$Sex=='male'])
#añadimos al dataset
muestra$FareGroups<-FareGroups
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$FareGroups),length)
names(countsClassVar) <- c("Survived","FareGroups","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=FareGroups)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del coste del ticket") +
  xlab("grupo Fare") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))

#podemos obtener un fare por persona dividiendo el coste entre el número de tickets iguales
FareIndividual<-muestra$Fare/muestra$TicketFreq
muestra$FareIndividual<-FareIndividual
#creamos grupos para faresindividuales
FareIndGroups<-cut(muestra$FareIndividual, 8, include.lowest=TRUE)
FareIndGroups<-as.character(FareIndGroups)
FareIndGroups[FareIndGroups %in% c("(96.1,112]","(112,128]")]<- '115'  
FareIndGroups<-as.factor(FareIndGroups)
levels(FareIndGroups) <- paste("FIG",as.character(as.integer(aggregate(muestra$Fare ~ FareIndGroups, FUN=function(x) {sum(x)/length(x)})$`muestra$Fare`)),sep='')
#mostramos frecuencia de los datos
table(FareIndGroups)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ FareIndGroups, FUN=function(x) {sum(x)/length(x)})
#vemos proporcion de supervivencia de los grupos y el sexo
aggregate(muestra$Survived ~ FareIndGroups+muestra$Sex, FUN=function(x) {sum(x)/length(x)})
table(FareIndGroups[muestra$Sex=='female'])
table(FareIndGroups[muestra$Sex=='male'])
#añadimos al dataset
muestra$FareIndGroups<-FareIndGroups
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$FareIndGroups),length)
names(countsClassVar) <- c("Survived","FareIndGroups","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=FareIndGroups)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del coste individual del ticket") +
  xlab("grupo individual Fare") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))

boxplot(muestra$FareIndividual,
        data = muestra,
        ylab = "FareIndividual del pasajero",
        main = "grafico de caja de FareIndividual") 
boxplot.stats(muestra$FareIndividual)$out 

boxplot(as.numeric(muestra$FareIndGroups),
        data = muestra,
        ylab = "FareIndGroups del pasajero",
        main = "grafico de caja de FareIndGroups") 
boxplot.stats(as.numeric(muestra$FareIndGroups))$out 

#Parece que hay una gran diferencia en la supervivencia del fare en función del sexo
#vamos a probar a crear una variable que sume el fare individual + el sexo * 40
monetizedSex<-ifelse(as.numeric(muestra$Sex)==1,1,0)*60
FareIndividualBySex<-FareIndividual+monetizedSex
#creamos grupos para faresindividuales
FareIndividualBySexGroups<-cut(FareIndividualBySex, 8, include.lowest=TRUE)
FareIndividualBySexGroups<-as.character(FareIndividualBySexGroups)
FareIndividualBySexGroups<-as.factor(FareIndividualBySexGroups)
levels(FareIndividualBySexGroups) <- paste("FIBSG",as.character(as.integer(aggregate(muestra$Fare ~ FareIndividualBySexGroups, FUN=function(x) {sum(x)/length(x)})$`muestra$Fare`)),sep='')
#mostramos frecuencia de los datos
table(FareIndividualBySexGroups)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ FareIndividualBySexGroups, FUN=function(x) {sum(x)/length(x)})

boxplot(FareIndividualBySex,
        data = muestra,
        ylab = "FareIndividualBySexGroups del pasajero",
        main = "grafico de caja de FareIndividualBySexGroups") 
boxplot.stats(FareIndividualBySex)$out 
boxplot(as.numeric(FareIndividualBySexGroups),
        data = muestra,
        ylab = "FareIndividualBySexGroups del pasajero",
        main = "grafico de caja de FareIndividualBySexGroups") 
boxplot.stats(as.numeric(FareIndividualBySexGroups))$out 

muestra$FareIndividualBySex<-FareIndividualBySex
muestra$FareIndividualBySexGroups<-FareIndividualBySexGroups
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$FareIndividualBySexGroups),length)
names(countsClassVar) <- c("Survived","FareIndividualBySexGroups","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=FareIndividualBySexGroups)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del coste modificado") +
  xlab("grupo coste modificado") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))


#-----------------------------------------------------------------------------------------------------------------------------------------
```
## Trabajo con Edad

```{r pruebas_mrzs_Edad, size="small"}
#TRABAJO CON EDAD
hist(muestra$Age, ylab="frecuencia absoluta", xlab="Age", breaks= 6, col="darkgray")
#usamos la función cut para separar en grupos o categorías
ageGroups<-cut(muestra$Age, 5, include.lowest=TRUE)
levels(ageGroups) <- paste("AG",as.character(as.integer(aggregate(muestra$Age ~ ageGroups, FUN=function(x) {sum(x)/length(x)})$`muestra$Age`)),sep='')
#mostramos frecuencia de los datos
table(ageGroups)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ ageGroups, FUN=function(x) {sum(x)/length(x)})
#vemos proporcion de supervivencia de los grupos y el sexo
aggregate(muestra$Survived ~ ageGroups+muestra$Sex, FUN=function(x) {sum(x)/length(x)})
#añadimos al dataset
muestra$ageGroupsByCut<-ageGroups


# LIMPIEZA 

#Imputamos los valores perdidos por la media de edad de cada titulo
muestra[is.na(muestra$Age),]
#obtenemos las edades medias de los grupos  
aggregate(muestra$Age ~ ageGroups, FUN=function(x) {sum(x)/length(x)})
#obtenemos las edades medias de los Titulos  
mediasTitulos<-aggregate(muestra$Age ~ Titulo, FUN=function(x) {sum(x)/length(x)})
#vemos cuantos valores perdidos hay dentro de cada Titulo
table(Titulo[is.na(muestra$Age)])
#asignamos la media del título a cada elemento
TitleAges <- mediasTitulos$`muestra$Age`[match(unlist(Titulo), mediasTitulos$Titulo)]
#Creamos una nueva variable en el dataset con todos los valores de Age + imputaciones
muestra$Ages <- ifelse(is.na(muestra$Age), TitleAges, muestra$Age)
#sustituimos en la columna buena
#VAMOS A PROBAR INICIALMENTE CON ESTE MÉTODO, PARECE MÁS FIABLE DE ENTRADA
#El resto de los metodos de imputación parecen algo pobres habría que pulirlos un poco
#muestra$Age <- ifelse(is.na(muestra$Age), TitleAges, muestra$Age)

#imputamos valores perdidos por KNN
# para imputar los valores perdidos Age vamos a usar las variables "Pclass","Sex","SibSp","Parch","Fare","Embarked","Titulo"
# pero hay que refactorizar los factores para pasarlo a numérico???
#tendríamos que escalar Fare?
# parece que funciona pero habría que asegurarse de si los factores valen sin refactorizar
dfinputaciones<-kNN(muestra, variable=c("Age"), dist_var=c("Pclass","Sex","SibSp","Parch","Fare","Embarked","Titulo",'FamSize'),k=3)
#extraemos las inputaciones de  Age
dfinputAge<-dfinputaciones[dfinputaciones$Age_imp=="TRUE",]
# Almacenamos los valores predichos de Age en la muestra
muestra$KNNAges<- dfinputaciones$Age
#comparamos predicciones, la de la media con la de KNN
tblAges<-cbind(muestra[is.na(muestra$Age),]$PassengerId,muestra[is.na(muestra$Age),]$Age,muestra[is.na(muestra$Age),]$Ages,muestra[is.na(muestra$Age),]$KNNAges, diferencia = muestra[is.na(muestra$Age),]$Ages - muestra[is.na(muestra$Age),]$KNNAges)
#comparamos valores obtenidos por KNN con los valores obtenidos por titulo
tblAges[order(abs(tblAges[,'diferencia']),decreasing=TRUE),]
#algunos valores se diferencian bastante


# Imputamos los valores perdidos con rpart
# no tengo muy controlados los arboles de decisión, habría que ver si esta bien creado o hay que optimizar
summary(muestra$Age)
#creamos el modelo para prediccion
Agefit <- rpart(Age ~ Pclass + Sex + SibSp + Parch + Fare + Embarked + Titulo + FamSize, data=muestra[!is.na(muestra$Age),],method="anova")
#predecimos los valores perdidos
RpartPredictedAges <- predict(Agefit, muestra[is.na(muestra$Age),])
# rellenamos la variable con los valores imputados, descomentar si se quieren usar estos valores para imputar
#muestra$Age[is.na(muestra$Age)] <- predict(Agefit, muestra[is.na(muestra$Age),])
tblAges<-cbind(muestra[is.na(muestra$Age),]$PassengerId,muestra[is.na(muestra$Age),]$Age,muestra[is.na(muestra$Age),]$Ages,muestra[is.na(muestra$Age),]$KNNAges,RpartPredictedAges, diferencia = muestra[is.na(muestra$Age),]$Ages - RpartPredictedAges, diferencia2 = muestra[is.na(muestra$Age),]$KNNAges - RpartPredictedAges)
#comparamos valores obtenidos por rpart con los valores obtenidos por titulo
tblAges[order(abs(tblAges[,'diferencia']),decreasing=TRUE),]
#observamos que en algunos valores hay bastante diferencia, hay una miss 129 con asignación de 7 años y varios master con asignaciones superiores a 16, lo que puede variar considerablemente las probabilidades de supervivencia


#por regresion
concat <- na.omit(muestra)
#mostramos histograma de la edad
ggplot(concat, aes(x=Age)) + 
  geom_histogram(binwidth=2,color="black", fill="white") +
  theme_bw() +
  ggtitle("Age histogram across passengers") +
  xlab("Age") + ylab("Observed Counts") + theme(plot.title = element_text(hjust = 0.5))

#habría que ver la distribución de las variables y ver si son normales, si hay homocedasticidad, independencia??
par(mfrow=c(1,1))
x1 <- muestra$Pclass
x2 <- muestra$SibSp
x3 <- muestra$Parch
x4 <- muestra$Fare
x5 <- muestra$Sex
x6 <- muestra$Embarked
x7 <- as.factor(muestra$IsMother)
x8 <-  as.factor(muestra$LoneWolfs)
x9 <- muestra$FamSize
x10 <- muestra$Titulo
#ajustamos los valores de referencia en los factores
x5 <- relevel(x5, ref = 'male')
x6 <- relevel(x6, ref = 'S')
x7 <- relevel(x7, ref = 'FALSE')
x8 <- relevel(x8, ref = 'TRUE')
x10 <- relevel(x10, ref = 'Mr')
y <- muestra$Age
#vemos correlación de variables cuantitativas
scatterplotMatrix(muestra[,c("Pclass","SibSp","Parch","Fare","FamSize")], diagonal=list(method ="histogram", breaks="FD"), smooth=FALSE)
#vemos correlación de cualitativas
ggplot(data = muestra, mapping=aes(x = x5, y = Age, color=x5)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")+
labs( title ="Relación de Sex y Age")  
ggplot(data = muestra, mapping=aes(x = x6, y = Age, color=x6)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")+
labs( title ="Relación de Embarked y Age")  
ggplot(data = muestra, mapping=aes(x = x7, y = Age, color=x7)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")+
labs( title ="Relación de IsMother y Age") 
ggplot(data = muestra, mapping=aes(x = x8, y = Age, color=x8)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")+
labs( title ="Relación de LoneWolf y Age") 
ggplot(data = muestra, mapping=aes(x = x10, y = Age, color=x10)) +
geom_boxplot() +
geom_jitter(width = 0.1) +
theme_bw() + theme(legend.position = "none")+
labs( title ="Relación de Titulo y Age") 

#estimacion del modelo1
#modelo_lineal_multiple <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10)
#quitamos famsize porque anula el vif al ser relacion de otras variables
modelo_lineal_multiple <- lm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x10)

print("Los coeficientes estimados son:")
modelo_lineal_multiple$coefficients
print("----------------------------------------------------------------------------------")
print("Resumen completo de los modelos")
summary(modelo_lineal_multiple)
summary.aov(modelo_lineal_multiple)
##Vamos a probar la significación de las variables por intervalos de confianza
print("Intervalos de confianza para la significación del modelo")
confint(modelo_lineal_multiple, level=0.999)
#esto muestra las gráficas de los residuos del modelo
par(mfrow=c(2,2))
plot(modelo_lineal_multiple)
par(mfrow=c(1,1))
plot( predict (modelo_lineal_multiple ), rstudent (modelo_lineal_multiple ))
print("Variance inflation factors")
vif(modelo_lineal_multiple)

#Obtenemos un modelo2 de regresión múltiple !Este usa el logaritmo de la edad y mejora un poco pero solo llegamos al coeficiente de determinación 0.55!
#habría que eliminar variables que no aportan y puede que estandarizar y normalizar variables
#Se pueden ir probando los resultados con la predicción y viendo si mejora la predicción de supervivientes
#fit <- lm(log(Age)~Pclass+SibSp+Parch+Fare+Sex+Embarked+isMother+allSurv+anySurv+noneSurv+loneP+            Deck+FamSize+FamSize2+Title+FarePP+TicketFreq+ticCode+ticLett,data = concat)
#fit <- lm(log(Age)~Pclass+SibSp+Parch+Fare+Sex+Embarked+IsMother+LoneWolfs+FamSize+Titulo,data = concat)
#quitamos famsize porque anula el vif al ser relacion de otras variables
fit <- lm(log(Age)~Pclass+SibSp+Parch+Fare+Sex+Embarked+IsMother+LoneWolfs+Titulo,data = concat)
print("Los coeficientes estimados son:")
fit$coefficients
print("----------------------------------------------------------------------------------")
print("Resumen completo de los modelos")
summary(fit)
summary.aov(fit)
##Vamos a probar la significación de las variables por intervalos de confianza
print("Intervalos de confianza para la significación del modelo")
confint(fit, level=0.999)
#esto muestra las gráficas de los residuos del modelo
par(mfrow=c(2,2))
plot(fit)
par(mfrow=c(1,1))
plot( predict (fit ), rstudent (fit ))
print("Variance inflation factors")
vif(fit)

#Nos quedamos con el segundo modelo que es mejor, pero hay que mejorar estos modelos
#porque como están son bastante malos, coeficientes de determinación que no llegan al 60%

#library(MASS, lib.loc = "/usr/lib/R/library") #hace falta para SepAIC
# no tengo muy claro que hace esto, parece que debería ser para escoger entre variables explicativas en funcion del AIC del modelo resultante, pero no lo se
step.model <- stepAIC(fit, direction = "both",trace = F) 
dummyIndex <- which(is.na(muestra$Age))
muestra$RegresionAges<- 0
#obtenemos las predicciones de la Edad
muestra$RegresionAges[dummyIndex] <- exp(predict(step.model, newdata = muestra[dummyIndex,]))
muestra$RegresionAges[muestra$RegresionAges==0]<-muestra$Ages[muestra$RegresionAges==0]
tblAges<-cbind(muestra[is.na(muestra$Age),]$PassengerId,muestra[is.na(muestra$Age),]$Age,muestra[is.na(muestra$Age),]$Ages,RpartPredictedAges,muestra[is.na(muestra$Age),]$RegresionAges, diferencia1  = muestra[is.na(muestra$Age),]$Ages - RpartPredictedAges, diferencia2  = muestra[is.na(muestra$Age),]$RegresionAges - RpartPredictedAges, diferencia3  = muestra[is.na(muestra$Age),]$RegresionAges - muestra[is.na(muestra$Age),]$Ages)
#comparamos valores obtenidos por regresion con los valores obtenidos por titulo
tblAges[order(abs(tblAges[,'diferencia2']),decreasing=TRUE),]
#comparamos valores obtenidos por regresion con los valores obtenidos por rpart
tblAges[order(abs(tblAges[,'diferencia3']),decreasing=TRUE),]

#OUTLIERS
boxplot(muestra$Age,ylab = "scaled Age del pasajero",main = "grafico de caja de  Age") 
boxplot.stats(muestra$Age)$out 


#sustituimos los NAs en la variable AGE
#VAMOS A PROBAR INICIALMENTE CON EL MÉTODO de las medias por titulo, PARECE MÁS FIABLE DE ENTRADA
#El resto de los metodos de imputación parecen algo pobres habría que pulirlos un poco
muestra$Age <- ifelse(is.na(muestra$Age), TitleAges, muestra$Age)

#VOLVEMOS A CREAR LOS GRUPOS DE EDAD TRAS ELIMINAR LOS Na
#usamos la función cut para separar en grupos o categorías
ageGroups<-cut(muestra$Age, 5, include.lowest=TRUE)
levels(ageGroups) <- paste("AG",as.character(as.integer(aggregate(muestra$Age ~ ageGroups, FUN=function(x) {sum(x)/length(x)})$`muestra$Age`)),sep='')
#mostramos frecuencia de los datos
table(ageGroups)
#vemos proporcion de supervivencia de los grupos
aggregate(muestra$Survived ~ ageGroups, FUN=function(x) {sum(x)/length(x)})
#vemos proporcion de supervivencia de los grupos y el sexo
aggregate(muestra$Survived ~ ageGroups+muestra$Sex, FUN=function(x) {sum(x)/length(x)})
#añadimos al dataset
muestra$ageGroupsByCut<-ageGroups
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$ageGroupsByCut),length)
names(countsClassVar) <- c("Survived","ageGroupsByCut","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=ageGroupsByCut)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función del grupo de edad") +
  xlab("grupo de edad") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))

#Nueva Variable pero parece que no vale para nada o está mal creada
#Young people travelling alone
muestra$youngTravelAl <- muestra$Age < 25 & muestra$Parch == 0
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$youngTravelAl),length)
names(countsClassVar) <- c("Survived","youngTravelAl","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=youngTravelAl)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función de si es joven viajando solo") +
  xlab("joven viaja solo") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))

#-----------------------------------------------------------------------------------------------------------------------------------------
#-----------------------------------------------------------------------------------------------------------------------------------------

```

## Trabajo con Pclass
Pclas está como integer pero realmente es una categórica, podemos crear una nueva varable tipo factor 

```{r pruebas_mrzs_Cabina, size="small"}

#TRABAJO CON PCLASS
#vamos a crear una variable con pclass factorizada

muestra$PclassFactor<-as.factor(muestra$Pclass)
#visualizacion grafica 
countsClassVar <- aggregate(muestra$Survived,by=list(muestra$Survived,muestra$PclassFactor),length)
names(countsClassVar) <- c("Survived","PclassFactor","Counts")
countsClassVar$Survived <- as.factor(countsClassVar$Survived)
ggplot(countsClassVar, aes(fill=Survived, y=Counts, x=PclassFactor)) + 
  geom_bar( stat="identity", position="fill") +
  theme_bw() +
  ggtitle("Supervivencia en función de la clase") +
  xlab("clase") + ylab("Survival Rate") + theme(plot.title = element_text(hjust = 0.5))


#-----------------------------------------------------------------------------------------------------------------------------------------
```




# Escalado, dummycode , relevel??, exponenciación Age


```{r pruebas_conversion, size="small"}

#Exponenciar variables numericas para apaliar la no linearidad
muestra.numeric <- muestra[c('Age', 'Fare')]
muestra[c('AgePw2','FarePw2')] <- muestra.numeric ^ 2
muestra[c('AgePw3','FarePw3')] <- muestra.numeric ^ 3

#Convertimos las variables char y logicas a factor
muestra$FamilyIDTKGroupedFactor<-as.factor(muestra$FamilyIDTKGrouped)


#conversion: PREPARAR VARIABLES
#"PassengerId","Survived","Pclass","Name","Sex","Age","SibSp","Parch","Ticket","Fare","Cabin","Embarked","TktNum","TktPre","tamanoticket","TicketFreq","Titulo","FamSize","LoneWolfs","FamilyIDTKGrouped","IsMother","scaledFare","FareGroups","FareIndividual","FareIndGroups","ageGroupsByCut","Ages","KNNAges","RegresionAges","scaledAge","FareIndividualBySex","FareIndividualBySexGroups"

#vamos a crear nuevas variables escaladas de todas las numéricas
#"Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex"
muestrascaledumy<-muestra
muestrascaledumy[, c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex")] <- scale(muestrascaledumy[, c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex")])
#las nuevas variables seran
muestra$PclassScaled <- muestrascaledumy$Pclass
muestra$AgeScaled <- muestrascaledumy$Age
muestra$SibSpScaled <- muestrascaledumy$SibSp  
muestra$ParchScaled <- muestrascaledumy$Parch
muestra$FareScaled <- muestrascaledumy$Fare 
muestra$tamanoticketScaled <- muestrascaledumy$tamanoticket
muestra$TicketFreqScaled <- muestrascaledumy$TicketFreq
muestra$FamSizeScaled <- muestrascaledumy$FamSize
muestra$FareIndividualScaled <- muestrascaledumy$FareIndividual
muestra$AgesScaled <- muestrascaledumy$Ages
muestra$KNNAgesScaled <- muestrascaledumy$KNNAges
muestra$RegresionAgesScaled <- muestrascaledumy$RegresionAges
muestra$FareIndividualBySexScaled <- muestrascaledumy$FareIndividualBySex

#Si queremos visualizar el gráfico de caja las nuevas variables escaladas
# boxplot(muestra$scaledAge,
#         data = muestra,
#         ylab = "scaled Age del pasajero",
#         main = "grafico de caja de scaled Age") 
# boxplot.stats(muestra$scaledAge)$out 



#Las variables categoricas tienen que ser dummy coded
#"Sex","Ticket","Embarked","Titulo","LoneWolfs","FamilyIDTKGrouped","IsMother","FareGroups","FareIndGroups","ageGroupsByCut","FareIndividualBySexGroups"
#We now dummy code variables that have just two levels and are coded 1/0.
muestrascaledumy$Sex <- ifelse(muestrascaledumy$Sex == "male", 1, 0)
muestrascaledumy$LoneWolfs <- ifelse(muestrascaledumy$LoneWolfs, 1, 0)
muestrascaledumy$IsMother <- ifelse(muestrascaledumy$IsMother, 1, 0)
muestrascaledumy$youngTravelAl  <- ifelse(muestrascaledumy$youngTravelAl, 1, 0)
#las nuevas variables seran
muestra$SexDummy <- muestrascaledumy$Sex
muestra$LoneWolfsDummy <- muestrascaledumy$LoneWolfs
muestra$IsMotherDummy <- muestrascaledumy$IsMother  
muestra$youngTravelAlDummy <- muestrascaledumy$youngTravelAl


#Next we dummy code variables that have three or more levels.
dmmyEmbarked <- as.data.frame(dummy.code(muestrascaledumy$Embarked))
dmmyFamilyIDTKGrouped <- as.data.frame(dummy.code(muestrascaledumy$FamilyIDTKGrouped))
dmmyTitulo <- as.data.frame(dummy.code(muestrascaledumy$Titulo))
dmmyFareGroups <- as.data.frame(dummy.code(muestrascaledumy$FareGroups))
dmmyFareIndGroups <- as.data.frame(dummy.code(muestrascaledumy$FareIndGroups))
dmmyageGroupsByCut <- as.data.frame(dummy.code(muestrascaledumy$ageGroupsByCut))
dmmyFareIndividualBySexGroups <- as.data.frame(dummy.code(muestrascaledumy$FareIndividualBySexGroups))
#Combine new dummy variables with original data set.
muestrascaledumy <- cbind(muestrascaledumy,dmmyEmbarked, dmmyFamilyIDTKGrouped, dmmyTitulo, dmmyFareGroups, dmmyFareIndGroups, dmmyageGroupsByCut, dmmyFareIndividualBySexGroups)

# Las variables dummy de factores de muchos niveles crean variables nuevas por cada uno de los niveles
# Es mejor probar con este dataset y si tal luego añadimos a la muestra los variablesdummy determinantes


```

# Seleccionamos posibles grupos de Variables para el análisis 


```{r Seleccion_grupos_variables, size="small"}

```



## Análisis de las variables por métodos de filtrado
Este análisis se basa en contrastar la correlación de la variables, estudiar por contrastes de hipótesis si la variables independientes tienen alguna variable que es dependiente entre las variables explicativas o viendo la information.gain de las variables(paquete FSelector)

```{r pruebas_analisis_filtros, size="small"}
#resumen estadístico de las variables del dataset sería un análisis estadístico
summary(muestra)

#"Pclass","Sex","SibSp","Parch","Fare","Embarked","Titulo",'FamSize','FamilyIDTKGrouped','IsMother','LoneWolfs','Age','TktNum'
#Mostramos matriz de correlaciones entre las variables numéricas independientes
auxmat <- cov2cor(cov.wt(cbind(muestra$Pclass,muestra$Age,muestra$SibSp,muestra$Parch,muestra$Fare,muestra$tamanoticket,muestra$TicketFreq,muestra$FamSize,muestra$FareIndividual,muestra$Ages,muestra$KNNAges,muestra$RegresionAges,as.numeric(muestra$FareIndividualBySex),as.numeric(muestra$FamilyIDTKGroupedFactor)))$cov)
colnames(auxmat)<-c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex","FamilyIDTKGrouped") 
rownames(auxmat)<-c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex","FamilyIDTKGrouped") 
auxmat
corrplot(cor(auxmat), method="number", is.corr=FALSE)

#Mostramos matriz de correlaciones y gráfico entre las variables numéricas independientes
dfaux<-muestra[,c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex")]
cor(dfaux)
corrplot(cor(dfaux), method="number", is.corr=FALSE)

#Mostramos matriz de correlaciones y gráfico entre las variables numéricas independientes añadiendo algunos factores dummy
dfaux<-muestra[,c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex","SexDummy","LoneWolfsDummy","IsMotherDummy","youngTravelAlDummy")]
cor(dfaux)
corrplot(cor(dfaux), method="number", is.corr=FALSE)


#Mostramos matriz de correlaciones y gráfico entre las variables numéricas independientes solo en el conjunto train
#y agregando survived para ver que relación tienen las var con survived
dfaux<-muestra[1:891,c("Survived","Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex","SexDummy","LoneWolfsDummy","IsMotherDummy","youngTravelAlDummy")]
cor(dfaux)
corrplot(cor(dfaux), method="number", is.corr=FALSE)

#Gráfico de correlación entre variables
tabla_contingencia <- xtabs(~Survived+Pclass, data=muestra)
# se comprueba por chisq.test()
chisqresult <- chisq.test(tabla_contingencia, correct = FALSE)
corrplot(chisqresult$residuals, is.cor = FALSE)

#Gráfico de correlación entre variables
tabla_contingencia <- xtabs(~Survived+FamilyIDTKGrouped, data=muestra)
# se comprueba por chisq.test()
chisqresult <- chisq.test(tabla_contingencia, correct = FALSE)
corrplot(chisqresult$residuals, is.cor = FALSE)



```
## Análisis de las variables por análisis de fatores

```{r pruebas_analisis_factores, size="small"}
#resumen estadístico de las variables del dataset sería un análisis estadístico
summary(muestra)


#Para realizar el análisis de componentes no tiene que haber Nas
#Preparamos un dataset sin Nas
# quitamos columnas NAs (1,2,4,11,13,14)
#noNaGroup<-muestra[,c(3,5,6,7,8,9,10,12,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32)]
#noNaGroup<-muestra[,-c(1,2,4,11,13,14)]
noNaGroup<-muestra[,-c(1,2,4,9,11,13,14)] #a 100 componentes un 99% habría que ver
#noNaGroup<-muestrascaledumy[,-c(1,2,4,11,13,14)] demasiadas variables??

noNaGroup <- noNaGroup %>% mutate_if(is.logical, as.factor)
#undertake a factor analysis of mixed data (note that quantitative variables are automatically scaled to unit variance here). 
res.famd <- FAMD(noNaGroup, ncp = 100,graph = F)
print(res.famd$eig[,-1])
#obtenemos unos valores muy raros, creo que no deberían tener correlacion

#scree plot and an overview of variable contributions to the first two dimensions.
# {r, echo=FALSE, fig.width=4.5, fig.height=4}
fviz_screeplot(res.famd, addlabels = TRUE)
fviz_famd_var(res.famd, col.var = "contrib", axes = c(1,2), ylim=c(-0.1,0.8), xlim=c(-0.1,0.95),repel = T,
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07") )


### New train and test data sets
#We thus create new train and test data sets, using the full projected data. We still retain the original data sets however, as these are more appropriate for models that deal with correlated variables on their on (i.e. Random Forests,...).
trainFAMD <- data.frame(muestra[,1:2],res.famd$ind$coord[1:nrow(muestra),1:100])

#Let us have a look at the (**train**) data projection across the principal dimensions, colour coded for survival.
ggplot(trainFAMD, aes(color=Survived, y=Dim.2, x=Dim.1)) +
  geom_point() + theme_bw() +  ggtitle("Passenger coordinates") +
  xlab("Dimension 1") + ylab("Dimension 2") + theme(plot.title = element_text(hjust = 0.5))
  
ggplot(trainFAMD, aes(color=Survived, y=Dim.4, x=Dim.3)) +
  geom_point() + theme_bw() +  ggtitle("Passenger coordinates") +
  xlab("Dimension 3") + ylab("Dimension 4") + theme(plot.title = element_text(hjust = 0.5))
   
ggplot(trainFAMD, aes(color=Survived, y=Dim.6, x=Dim.5)) +
  geom_point() + theme_bw() +  ggtitle("Passenger coordinates") +
  xlab("Dimension 5") + ylab("Dimension 6") + theme(plot.title = element_text(hjust = 0.5))

ggplot(trainFAMD, aes(color=Survived, y=Dim.8, x=Dim.7)) +
  geom_point() + theme_bw() +  ggtitle("Passenger coordinates") +
  xlab("Dimension 7") + ylab("Dimension 8") + theme(plot.title = element_text(hjust = 0.5))

ggplot(trainFAMD, aes(color=Survived, y=Dim.10, x=Dim.9)) +
  geom_point() + theme_bw() +  ggtitle("Passenger coordinates") +
  xlab("Dimension 9") + ylab("Dimension 10") + theme(plot.title = element_text(hjust = 0.5))

ggplot(trainFAMD, aes(color=Survived, y=Dim.12, x=Dim.11)) +
  geom_point() + theme_bw() +  ggtitle("Passenger coordinates") +
  xlab("Dimension 11") + ylab("Dimension 12") + theme(plot.title = element_text(hjust = 0.5))

 



 

```

## Análisis de las variables por Forward Selection, Backward Selection, Stepwise Selection

```{r pruebas_analisis_wrapper_methods, size="small"}

# Using stepAIC function 
#primero hay que crear un modelo y luego se otimiza
# Partimos el dataset en los conjuntos iniciales de train y test.
#"PassengerId","Survived","Pclass","Name","Sex","Age","SibSp","Parch","Ticket","Fare","Cabin","Embarked","TktNum","TktPre","tamanoticket","TicketFreq","Titulo","FamSize","LoneWolfs","FamilyIDTKGrouped","IsMother","FareGroups","FareIndividual","FareIndGroups","FareIndividualBySex","FareIndividualBySexGroups","ageGroupsByCut","Ages","KNNAges","RegresionAges","youngTravelAl","PclassFactor","AgePw2","FarePw2","AgePw3","FarePw3","FamilyIDTKGroupedFactor","PclassScaled","AgeScaled","SibSpScaled","ParchScaled","FareScaled","tamanoticketScaled","TicketFreqScaled","FamSizeScaled","FareIndividualScaled","AgesScaled","KNNAgesScaled","RegresionAgesScaled","FareIndividualBySexScaled","SexDummy","LoneWolfsDummy","IsMotherDummy","youngTravelAlDummy"
#trainAIC <- muestra[1:891,-c(4,9,11,13,14,20)]
#testAIC <- muestra[892:1309,-c(4,9,11,13,14,20)]
trainAIC <- muestra[1:891,c("Survived","Embarked","Titulo","FareIndGroups","FareIndividualBySexGroups","ageGroupsByCut","PclassFactor","FamilyIDTKGroupedFactor","AgeScaled","SibSpScaled","ParchScaled","tamanoticketScaled","TicketFreqScaled","FareIndividualScaled","FareIndividualBySexScaled","LoneWolfsDummy","IsMotherDummy","youngTravelAlDummy")]
testAIC <- muestra[892:1309,c(4,9,11,13,14,20)]
trainFamdAIC <- trainFAMD[1:891,]
testFamdAIC <- trainFAMD[892:1309,]
trainSdAIC <- muestrascaledumy[1:891,-c(4,9,11,13,14,20)]
testSdAIC <- muestrascaledumy[892:1309,-c(4,9,11,13,14,20)]


#ajustamos los valores de referencia en los factores
trainAIC <- trainAIC %>% mutate_if(is.logical, as.factor)
#trainAIC$Sex <- relevel(trainAIC$Sex, ref = 'male')
trainAIC$Embarked<- relevel(trainAIC$Embarked, ref = 'S')
#trainAIC$IsMother <- relevel(trainAIC$IsMother, ref = 'FALSE')
#trainAIC$LoneWolfs <- relevel(trainAIC$LoneWolfs, ref = 'TRUE')
trainAIC$Titulo <- relevel(trainAIC$Titulo, ref = 'Mr')
trainAIC$FamilyIDTKGroupedFactor <- relevel(trainAIC$FamilyIDTKGroupedFactor, ref = 'Alone')
trainAIC$FareIndividualBySexGroups <- relevel(trainAIC$FareIndividualBySexGroups, ref = 'FIBSG14')
trainAIC$ageGroupsByCut <- relevel(trainAIC$ageGroupsByCut, ref = 'AG7')
#trainAIC$youngTravelAl <- relevel(trainAIC$youngTravelAl, ref = 'FALSE')

#Mostramos matriz de correlaciones y gráfico entre las variables numéricas independientes añadiendo algunos factores dummy
#dfaux<-trainAIC[,c("AgeScaled","SibSpScaled","ParchScaled","FareScaled","tamanoticketScaled","TicketFreqScaled","FamSizeScaled","FareIndividualScaled","FareIndividualBySexScaled","SexDummy","LoneWolfsDummy","IsMotherDummy","youngTravelAlDummy")]
#cor(dfaux)
#corrplot(cor(dfaux), method="number", is.corr=FALSE)

#mymod1<-glm(Survived ~ Titulo+FareIndividualBySexScaled+FamilyIDTKGroupedFactor, data = trainAIC ,binomial) #85% es la seleccion optima de rlm
#mymod1<-glm(Survived ~ Titulo+FareIndividual+PclassScaled+FamilyIDTKGroupedFactor, data = trainRlm ,binomial) #85% es la seleccion optima de rlm
#mymod1<-glm(Survived ~ TicketFreq+Titulo+FareIndividualBySex+PclassFactor+AgePw3, data = trainRlm ,binomial) #83.8% es la seleccion optima de rlm
#mymod1<-glm(Survived ~ FareIndividualBySex+FareIndividualBySexScaled+Titulo+KNNAgesScaled+FareIndividual, data = trainRFE ,binomial) #80.3% es la seleccion optima RFE
#mymod1<-glm(Survived ~ FareIndividualBySex+Titulo+KNNAgesScaled+PclassScaled+TicketFreq+FamSize+Embarked+SexDummy+youngTravelAl+tamanoticket, data = trainRFE ,binomial) #84.3% y 83.7 con AIC 
mymod1 <- glm(Survived ~ ., data = trainAIC ,binomial) #87% con optimal cutoff sin AIC
#mymod2 <- glm(Survived ~ ., data = trainFamdAIC, binomial)#85.6
#mymod1<-mymod2
#mymod3 <- glm(Survived ~ ., data = trainSdAIC, binomial)


#analisis de las variables del modelo
mymod1<-stepAIC(mymod1, direction = "both", trace = FALSE) #optimizado pierde. 86%
#stepAIC(mymod1, direction = "backward", trace = FALSE)
#stepAIC(mymod1, direction = "forward", trace = FALSE)

## vamos a ver los resultados del modelo para ver que tal lo hace
probabilidades <- predict(mymod1, type="response") 
# si la predicción supera el 50% se asigna a peso bajo
predicciones <- ifelse(probabilidades > 0.5, "Sobrevive", "No Sobrevive")
optCutOff <- optimalCutoff(mymod1$y, fitted(mymod1))[1] 
print("Porcentaje de corte óptimo")
optCutOff
#vamos a optimizar el modelo con el nuevo cutoff
prediccionesOptimizadas <- ifelse(probabilidades > optCutOff, "Sobrevive", "No Sobrevive")
#Misclassification Error
#Misclassification error is the percentage mismatch of predcited vs actuals, irrespective of 1’s or 0’s. The lower the misclassification error, the better is your model.
print(paste("Error por fallo de mala clasificación corte=",optCutOff))
misClassError(mymod1$y, fitted(mymod1), threshold = optCutOff)
print("Error por fallo de mala clasificación corte 0.5")
misClassError(mymod1$y, fitted(mymod1), threshold = 0.5)

#Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
t_cont_prediccion_contra_observación<- xtabs(~Survived+as.factor(predicciones), data=trainAIC)
print("Tabla de contingencia de predicciones contra observaciones Survived")
t_cont_prediccion_contra_observación
sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
total_elementos <- sum(t_cont_prediccion_contra_observación)
# obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
porcentaje_de_acierto
print("Matriz de porcentage de aciertos del modelo")
matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
print("acierto general del modelo")
acierto_tortal <-  (t_cont_prediccion_contra_observación[1,1]+t_cont_prediccion_contra_observación[2,2])/total_elementos
acierto_tortal
kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo. acierto global:",acierto_tortal))%>%
kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
add_header_above(c(" ", "(Prediccion peso)" = 2," "), bold = T, italic = T)%>%
pack_rows("(Observacioens peso)", 1, 2)

print("----------------------------------------------------------------------------------")
#OPTIMIZADO Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
t_cont_prediccion_contra_observación<- xtabs(~Survived+as.factor(prediccionesOptimizadas), data=trainAIC)
print("Tabla de contingencia de predicciones optimizadas peso contra observaciones peso")
t_cont_prediccion_contra_observación
print("----------------------------------------------------------------------------------")
sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
total_elementos <- sum(t_cont_prediccion_contra_observación)
# obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
print("----------------------------------------------------------------------------------")
matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
acierto_tortal <-
  (t_cont_prediccion_contra_observación[1, 1] + t_cont_prediccion_contra_observación[2, 2]) /
  total_elementos
print(paste("Porcentaje de acierto general del modelo: ",acierto_tortal))
print("Matriz de porcentage de aciertos del modelo optimizado")
kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo optimizado. acierto global:",acierto_tortal))%>%
kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
add_header_above(c(" ", "(Prediccion peso)" = 2," "), bold = T, italic = T)%>%
pack_rows("(Observacioens peso)", 1, 2) 

```

## Análisis de las variables por Forward Selection, Backward Selectio con paquete mlr

```{r pruebas_analisis_FS_BS_rlm, size="small"}

trainRlm <- muestrascaledumy[1:891,-c(4,9,11,13,14,20)]
#trainRlm <- muestra[1:891,-c(4,9,11,13,14,20)]
trainRlm <- trainRlm %>% mutate_if(is.logical, as.factor)
# trainRlm$Embarked<-as.factor(as.character(trainRlm$Embarked))
# #levels(trainRlm$Embarked)<-c("Cherbourg", "Queenstown", "Southampton")
# trainRlm$FamilyIDTKGroupedFactor<-as.character(trainRlm$FamilyIDTKGroupedFactor)
# trainRlm$FamilyIDTKGroupedFactor <- sub(' ', '-', trainRlm$FamilyIDTKGroupedFactor)
# trainRlm$FamilyIDTKGroupedFactor<-as.factor(trainRlm$FamilyIDTKGroupedFactor)

trainRlm.task<-makeClassifTask(data = trainRlm, target = "Survived")

# Creating sample instances
rdesc = makeResampleDesc("Holdout")
 
# Setting the Sequential forward Search - "sfs" 
# for Sequential Backward Search - "sbs""
ctrl = makeFeatSelControlSequential(method = "sfs", maxit = NA)
 
# Running the selection algorithm
res = selectFeatures("classif.rpart", trainRlm.task, rdesc, control = ctrl)
# Priting the final result.
analyzeFeatSelResult(res)

 

```

## Análisis de las variables por Recursive Feature Elimination Method (RFE)

```{r pruebas_analisis_rfe, size="small"}
#quitamos el 37 por el limite máximo de categorias
trainRFE <- muestrascaledumy[1:891,-c(4,9,11,13,14,20,37)]
#trainRFE <- muestra[1:891,-c(4,9,11,13,14,20,37)]

#library(caret)
set.seed(86)
inTrain <- createDataPartition(y = trainRFE[,2], p = .75, list = FALSE)
training <- trainRFE[ inTrain,]
testing <- trainRFE[-inTrain,]
 
# Setting the cross validation parameters
ctrl_param <- rfeControl(functions = rfFuncs,
                   method = "repeatedcv",
                   repeats = 5,
                   verbose = FALSE,
                   returnResamp = "all")
 
# 
rfe_lm_profile <- rfe(training[, -2], training[, 2],
                 sizes = c(2,3,4,5),
                 rfeControl = ctrl_param,
                 newdata = testing[, -2])
 
rfe_lm_profile

# Calculating variable importance
varImp(rfe_lm_profile)
#mas importantes FareIndividualBySex, FareIndividualBySexScaled, Titulo, KNNAgesScaled, FareIndividual
```

## Análisis de las variables Using Rcaret package(glm,) y métricas de bondad por la gráfica ROC

```{r pruebas_analisis_rcaret, size="small"}
#Remove Redundant Features
# ensure the results are repeatable
set.seed(7)
# load the library
#library(mlbench)
#library(caret)
# calculate correlation matrix
correlationMatrix <- cor(muestra[,c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex","SexDummy","LoneWolfsDummy","IsMotherDummy","youngTravelAlDummy")])
# summarize the correlation matrix
print(correlationMatrix)
# find attributes that are highly corrected (ideally >0.75)
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.5)
# print indexes of highly correlated attributes
print(highlyCorrelated)

#Rank Features By Importance
# ensure results are repeatable
set.seed(7)
# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- caret::train(Survived~., data=muestra[1:891,-c(4,9,11,13,14,20)], method="lvq", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)
# summarize importance
print(importance)
# plot importance
plot(importance)

#Feature Selection
# ensure the results are repeatable
set.seed(7)
# define the control using a random forest selection function
control <- rfeControl(functions=rfFuncs, method="cv", number=10)
# run the RFE algorithm
results <- rfe(muestrascaledumy[1:891,-c(2,4,9,11,13,14,20,37)], muestrascaledumy[1:891,2], sizes=c(1:8), rfeControl=control)
# summarize the results
print(results)
# list the chosen features
predictors(results)
# plot the results
plot(results, type=c("g", "o"))


```

## Análisis de las variables RandomForest

```{r pruebas_analisis_RForest, size="small"}
#quitamos el 37 por el limite máximo de categorias
trainRF <- muestrascaledumy[1:891,-c(4,9,11,13,14,20,37)]
testRF <- muestrascaledumy[892:1309,-c(4,9,11,13,14,20,37)]
#trainRF <- muestra[1:891,-c(4,9,11,13,14,20)]
#testRF <- muestrascaledumy[892:1309,-c(4,9,11,13,14,20,37)]


# Using random forest for variable selection
rfModel <-randomForest(Survived ~ ., data = trainRF)
 
# Getting the list of important variables
print('Importancia de las variables')
importance(rfModel)

# Vemos la importancia de las variables
print('Importancia de las variables 2')
varImpPlot(rfModel)

```

## Análisis de las variables con Random KNN for variable selection

```{r pruebas_analisis_RKNN, size="small"}
# ya no esta en cran library(knnTree)
# no se instala correctamente library(rknn)


```





## Prediccion por Random Forest

```{r pruebas_predict_rf, size="small"}
# Partimos el dataset en los conjuntos iniciales de train y test.
train2 <- muestra[1:891,]
test2 <- muestra[892:1309,]

#creamos un conjunto de entrenamiento y test propios a partir de train para calcular nuestros porcentaje de acierto
## 85% of the sample size
smp_size <- floor(0.85 * nrow(train2))
## Establecemos una semilla para poder volver a reproducir el mismo muestreo
set.seed(123)
train_ind <- sample(seq_len(nrow(train2)), size = smp_size)
train3 <- train2[train_ind, ]
test3 <- train2[-train_ind, ]
test3Survival<-test3$Survived
test3$Survived <- NA

#modelo para predicción por random forest
set.seed(400)
fit <- randomForest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Titulo + FamSize,
                      data=train3, 
                      importance=TRUE, 
                      ntree=2000)

# Vemos la importancia de las variables
varImpPlot(fit)
# hacemos la predicción y la guardamos en formato de envio 
Prediction <- predict(fit, test3)
submittest3 <- data.frame(PassengerId = test3$PassengerId, Survived = Prediction)
#pasamos dataset a fichero
#write.csv(submit, file = "firstforest.csv", row.names = FALSE)

#Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
t_cont_prediccion_contra_observación<- xtabs(~test3Survival+submittest3$Survived)
print("Tabla de contingencia de predicciones survived contra observaciones survived")
t_cont_prediccion_contra_observación
sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
total_elementos <- sum(t_cont_prediccion_contra_observación)
# obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
porcentaje_de_acierto
print("Matriz de porcentage de aciertos del modelo")
matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
print("acierto general del modelo")
acierto_tortal <-  (t_cont_prediccion_contra_observación[1,1]+t_cont_prediccion_contra_observación[2,2])/total_elementos
acierto_tortal
kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo. acierto global:",acierto_tortal))%>%
kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
add_header_above(c(" ", "(Prediccion survival)" = 2," "), bold = T, italic = T)%>%
pack_rows("(Observacioens survival)", 1, 2)



# Predicciones por condition inference tree Random Forest
## set the seed to make your partition reproducible
set.seed(123)
#creamos un conjunto de entrenamiento y test propios a partir de train
train3<-train2
#convertimos a factor la agrupacion por familias para poder usarlo en el cforest
train3$FamilyIDTKGrouped<-as.factor(train3$FamilyIDTKGrouped)
#creamos un conjunto de entrenamiento y test propios a partir de train para calcular nuestros porcentaje de acierto
## 85% of the sample size
smp_size <- floor(0.85 * nrow(train3))
train_ind <- sample(seq_len(nrow(train3)), size = smp_size)
train4 <- train3[train_ind, ]
test4 <- train3[-train_ind, ]
test4Survival<-test4$Survived
test4$Survived <- NA

set.seed(400)
fit <- cforest(as.factor(Survived) ~ Pclass + Sex + Age + SibSp + Parch + Fare + Embarked + Titulo + FamSize +FamilyIDTKGrouped,
               data = train4, controls=cforest_unbiased(ntree=2000, mtry=3)) 
# hacemos la predicción y la guardamos en formato de envio 
Prediction <- predict(object = fit, newdata=test4, OOB=TRUE, type = "response")
submittest3cf <- data.frame(PassengerId = test3$PassengerId, Survived = Prediction)
#escribimos fichero
#write.csv(submit, file = "ciforest.csv", row.names = FALSE)
#Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
t_cont_prediccion_contra_observación<- xtabs(~test4Survival+submittest3cf$Survived)
print("Tabla de contingencia de predicciones survival contra observaciones survival")
t_cont_prediccion_contra_observación
sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
total_elementos <- sum(t_cont_prediccion_contra_observación)
# obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
porcentaje_de_acierto
print("Matriz de porcentage de aciertos del modelo")
matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
print("acierto general del modelo")
acierto_tortal <-  (t_cont_prediccion_contra_observación[1,1]+t_cont_prediccion_contra_observación[2,2])/total_elementos
acierto_tortal
kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo. acierto global:",acierto_tortal))%>%
kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
add_header_above(c(" ", "(Prediccion survival)" = 2," "), bold = T, italic = T)%>%
pack_rows("(Observacioens survival)", 1, 2)


```

## Predicción por KNN

```{r pruebas_predict_knn, size="small"}

# Predicciones por KNN
## set the seed to make your partition reproducible
set.seed(123)
#creamos un conjunto de entrenamiento y test propios a partir de train
train3<-train2
#convertimos a factor las variables lógicas
train3 <- train3 %>% mutate_if(is.logical, as.factor)
#creamos un conjunto de entrenamiento y test propios a partir de train para calcular nuestros porcentaje de acierto
## 85% of the sample size
smp_size <- floor(0.85 * nrow(train3))
train_ind <- sample(seq_len(nrow(train3)), size = smp_size)
train4 <- train3[train_ind, ]
test4 <- train3[-train_ind, ]
#quitamos los valores observados para comparar efectividad
test4Survival<-test4$Survived
#Ponemos Nas en survived de nuestro test  
test4$Survived <- NA
#Volvemos a concatenar para usar KNN
train3<-rbind(train4,test4)

#PREPARAR VARIABLES
#"PassengerId","Survived","Pclass","Name","Sex","Age","SibSp","Parch","Ticket","Fare","Cabin","Embarked","TktNum","TktPre","tamanoticket","TicketFreq","Titulo","FamSize","LoneWolfs","FamilyIDTKGrouped","IsMother","scaledFare","FareGroups","FareIndividual","FareIndGroups","ageGroupsByCut","Ages","KNNAges","RegresionAges","scaledAge","FareIndividualBySex","FareIndividualBySexGroups"

#Las variables numericas deben ser escaladas Age y Fare ya tienen scaled
#"Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex"
train3scaledumy<-train3
train3scaledumy[, c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex")] <- scale(train3scaledumy[, c("Pclass","Age","SibSp","Parch","Fare","tamanoticket","TicketFreq","FamSize","FareIndividual","Ages","KNNAges","RegresionAges","FareIndividualBySex")])

#Las variables categoricas tienen que ser dummy coded
#"Sex","Ticket","Embarked","Titulo","LoneWolfs","FamilyIDTKGrouped","IsMother","FareGroups","FareIndGroups","ageGroupsByCut","FareIndividualBySexGroups"
#We now dummy code variables that have just two levels and are coded 1/0.
train3scaledumy$Sex <- ifelse(train3scaledumy$Sex == "yes", 1, 0)
train3scaledumy$LoneWolfs <- ifelse(train3scaledumy$LoneWolfs == "yes", 1, 0)
train3scaledumy$IsMother <- ifelse(train3scaledumy$IsMother == "yes", 1, 0)
#Next we dummy code variables that have three or more levels.
dmmyEmbarked <- as.data.frame(dummy.code(train3scaledumy$Embarked))
dmmyFamilyIDTKGrouped <- as.data.frame(dummy.code(train3scaledumy$FamilyIDTKGrouped))
dmmyTitulo <- as.data.frame(dummy.code(train3scaledumy$Titulo))
dmmyFareGroups <- as.data.frame(dummy.code(train3scaledumy$FareGroups))
dmmyFareIndGroups <- as.data.frame(dummy.code(train3scaledumy$FareIndGroups))
dmmyageGroupsByCut <- as.data.frame(dummy.code(train3scaledumy$ageGroupsByCut))
dmmyFareIndividualBySexGroups <- as.data.frame(dummy.code(train3scaledumy$FareIndividualBySexGroups))
#Combine new dummy variables with original data set.
train3scaledumy <- cbind(train3scaledumy,dmmyEmbarked, dmmyFamilyIDTKGrouped, dmmyTitulo, dmmyFareGroups, dmmyFareIndGroups, dmmyageGroupsByCut, dmmyFareIndividualBySexGroups)



#imputamos valores perdidos por KNN

# pero hay que refactorizar?? los factores para pasarlo a numérico???
# parece que funciona pero habría que asegurarse de si los factores valen sin refactorizar
#0.80
#dfinputaciones<-kNN(train3, variable=c("Survived"), dist_var=c("Pclass","Sex","SibSp","Parch","Fare","Embarked","Titulo",'FamSize','FamilyIDTKGrouped','IsMother','LoneWolfs','Age','TktNum'),k=25)
#0.835
#dfinputaciones<-kNN(train3scaledumy, variable=c("Survived"), dist_var=c("Pclass","Sex","SibSp","Parch","Fare","Embarked","Titulo",'FamSize','FamilyIDTKGrouped','IsMother','LoneWolfs','Age','TktNum'),k=25)
#0.835
dfinputaciones<-kNN(train3scaledumy, variable=c("Survived"), dist_var=c("Pclass","SibSp","Parch","tamanoticket","TicketFreq","FamSize","FareIndividualBySex","Sex",'IsMother','LoneWolfs',"Mr","Miss","Mrs","Master","titulogrupo0","Dr","titulogrupo1","titulogrupo05","(16.1,32.1]","(32.1,48.1]","[0.0902,16.1]","(48.1,64]","(64,80.1]"),k=25)


#extraemos las inputaciones de  Survived
dfinputSurvived<-dfinputaciones[dfinputaciones$Survived_imp=="TRUE",]
# Almacenamos los valores predichos de Survived para enviar
KNNsurvived<-dfinputSurvived$Survived
submittest3cf <- data.frame(PassengerId = test4$PassengerId, Survived = KNNsurvived)
#escribimos fichero
#write.csv(submit, file = "knn.csv", row.names = FALSE)
#Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
t_cont_prediccion_contra_observación<- xtabs(~test4Survival+submittest3cf$Survived)
print("Tabla de contingencia de predicciones survival contra observaciones survival")
t_cont_prediccion_contra_observación
sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
total_elementos <- sum(t_cont_prediccion_contra_observación)
# obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
porcentaje_de_acierto
print("Matriz de porcentage de aciertos del modelo")
matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
print("acierto general del modelo")
acierto_tortal <-  (t_cont_prediccion_contra_observación[1,1]+t_cont_prediccion_contra_observación[2,2])/total_elementos
acierto_tortal
kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo. acierto global:",acierto_tortal))%>%
kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
add_header_above(c(" ", "(Prediccion survival)" = 2," "), bold = T, italic = T)%>%
pack_rows("(Observacioens survival)", 1, 2)


```

## Predicción por regresión logística

```{r pruebas_predict_rl, size="small"}
# Partimos el dataset en los conjuntos iniciales de train y test.
train2 <- muestra[1:891,]
test2 <- muestra[892:1309,]

#Vamos a analizar la relación entre las variables



#estudio sexo
tabla_contingencia <- xtabs(~Survived+Sex, data=train2)
print("Tabla de contingencia de sex vs. survived")
tabla_contingencia
#test de independencia
chisq.test(tabla_contingencia)
#Cálculo de odds ratio
my_odds_ratio <- with(train2, (tabla_contingencia[1,1]*tabla_contingencia[2,2])/(tabla_contingencia[1,2]*tabla_contingencia[2,1]))
print("Odds ratio de sex vs. survived")
my_odds_ratio
#Gráfico de correlación entre variables
chisqresult <- chisq.test(tabla_contingencia, correct = FALSE)
corrplot(chisqresult$residuals, is.cor = FALSE)

#estudio Pclass
tabla_contingencia <- xtabs(~Survived+Pclass, data=train2)
print("Tabla de contingencia de Pclass vs. survived")
tabla_contingencia
#test de independencia
chisq.test(tabla_contingencia)
#Cálculo de odds ratio
my_odds_ratio <- with(train2, (tabla_contingencia[1,1]*tabla_contingencia[2,2])/(tabla_contingencia[1,2]*tabla_contingencia[2,1]))
print("Odds ratio de sex Pclass survived")
my_odds_ratio
#Gráfico de correlación entre variables
chisqresult <- chisq.test(tabla_contingencia, correct = FALSE)
corrplot(chisqresult$residuals, is.cor = FALSE)

#estudio sexo vs Pclass
tabla_contingencia <- xtabs(~Pclass+Sex, data=train2)
print("Tabla de contingencia de sex vs. Pclass")
tabla_contingencia
#test de independencia
chisq.test(tabla_contingencia)
#Cálculo de odds ratio
my_odds_ratio <- with(train2, (tabla_contingencia[1,1]*tabla_contingencia[2,2])/(tabla_contingencia[1,2]*tabla_contingencia[2,1]))
print("Odds ratio de sex vs. Pclass")
my_odds_ratio
#Gráfico de correlación entre variables
chisqresult <- chisq.test(tabla_contingencia, correct = FALSE)
corrplot(chisqresult$residuals, is.cor = FALSE)

#"Pclass","Sex","SibSp","Parch","Fare","Embarked","Titulo",'FamilyIDTKGrouped','IsMother','LoneWolfs',"Age",'TktNum'
x1 <- train2$Pclass
x2 <- train2$SibSp
x3 <- train2$Parch
x4 <- train2$Fare
x5 <- train2$Sex
x6 <- train2$Embarked
x7 <- as.factor(train2$IsMother)
x8 <- as.factor(train2$LoneWolfs)
x9 <- train2$FamSize
x10 <- train2$Titulo
x11 <- as.factor(train2$FamilyIDTKGrouped)
x12 <- train2$TicketFreq
x13 <- train2$Age
x14 <- train2$FareIndividual
x15 <- train2$FareIndGroups
x16 <- train2$FareGroups
x17 <- train2$ageGroupsByCut
#ajustamos los valores de referencia en los factores
x5 <- relevel(x5, ref = 'male')
x6 <- relevel(x6, ref = 'S')
x7 <- relevel(x7, ref = 'FALSE')
x8 <- relevel(x8, ref = 'TRUE')
x10 <- relevel(x10, ref = 'Mr')
x11 <- relevel(x11, ref = 'Alone')
y <- train2$Survived

#mymod3 <- glm(y ~ x1+x2+x3+x4+x5+x6+x7+x8+x9+x10+x11+x12+x13, binomial)
#mymod3 <- glm(y ~ x1+x2+x3+x4+x5+x13, binomial)
#mymod3 <- glm(y ~ x1+x2+x5+x13, binomial)
#mymod3 <- glm(y ~ x1+x2+x5+x10+x13, binomial)
#mymod3 <- glm(y ~ x1+x2+x10+x13, binomial)
##mymod3 <- glm(y ~ x1+x2+x9+x10+x13, binomial)
#mymod3 <- glm(y ~ x1+x2+x12+x10+x13, binomial)
##mymod3 <- glm(y ~ x1+x2+x11+x10+x13, binomial)
###mymod3 <- glm(y ~ x1+x2+x11+x10+x17+x15, binomial)
mymod3 <- glm(y ~ x1+x2+x12+x10+x11+x17+x15, binomial)
summary(mymod3)
#table(y) 
#confint(mymod3) # 95% CI for the coefficients
#exp(coef(mymod3)) # exponentiated coefficients (odds?? Sí, OddsRatio) 
#exp(confint(mymod3)) # 95% CI for exponentiated coefficients (Intervalo de confianza de las OR)
#residuals(mymod3, type="deviance") # residuals

## vamos a ver los resultados del modelo para ver que tal lo hace
probabilidades <- predict(mymod3, type="response") 
# si la predicción supera el 50% se asigna a peso bajo
predicciones <- ifelse(probabilidades > 0.5, "Sobrevive", "No Sobrevive")

# print("Tabla de contingencia de peso contra diámetro abdominal")
# t_cont_peso_AD
# t_cont_prediccion_peso_fumadora_ad<- xtabs(~as.factor(predicciones)+AD, data=muestra)
# print("Tabla de contingencia de predicciones peso contra diámetro abdominal")
# t_cont_prediccion_peso_fumadora_ad
# print("Tabla de contingencia de peso contra City")
# t_cont_peso_City
# t_cont_prediccion_peso_fumadora_city<- xtabs(~as.factor(predicciones)+City, data=muestra)
# print("Tabla de contingencia de predicciones peso contra city")
# t_cont_prediccion_peso_fumadora_city

#Decide on optimal prediction probability cutoff for the model
#The default cutoff prediction probability score is 0.5 or the ratio of 1’s and 0’s in the training data. But sometimes, tuning the probability cutoff can improve the accuracy in both the development and validation samples. The InformationValue::optimalCutoff function provides ways to find the optimal cutoff to improve the prediction of 1’s, 0’s, both 1’s and 0’s and o reduce the misclassification error. Lets compute the optimal score that minimizes the misclassification error for the above model.
#library(InformationValue)
optCutOff <- optimalCutoff(mymod3$y, fitted(mymod3))[1] 
print("Porcentaje de corte óptimo")
optCutOff
#vamos a optimizar el modelo con el nuevo cutoff
prediccionesOptimizadas <- ifelse(probabilidades > optCutOff, "Sobrevive", "No Sobrevive")

#Misclassification Error
#Misclassification error is the percentage mismatch of predcited vs actuals, irrespective of 1’s or 0’s. The lower the misclassification error, the better is your model.
print(paste("Error por fallo de mala clasificación corte=",optCutOff))
misClassError(mymod3$y, fitted(mymod3), threshold = optCutOff)
print("Error por fallo de mala clasificación corte 0.5")
misClassError(mymod3$y, fitted(mymod3), threshold = 0.5)

#Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
t_cont_prediccion_contra_observación<- xtabs(~Survived+as.factor(predicciones), data=train2)
print("Tabla de contingencia de predicciones contra observaciones Survived")
t_cont_prediccion_contra_observación
sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
total_elementos <- sum(t_cont_prediccion_contra_observación)
# obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
porcentaje_de_acierto
print("Matriz de porcentage de aciertos del modelo")
matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
print("acierto general del modelo")
acierto_tortal <-  (t_cont_prediccion_contra_observación[1,1]+t_cont_prediccion_contra_observación[2,2])/total_elementos
acierto_tortal
kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo. acierto global:",acierto_tortal))%>%
kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
add_header_above(c(" ", "(Prediccion peso)" = 2," "), bold = T, italic = T)%>%
pack_rows("(Observacioens peso)", 1, 2)

print("----------------------------------------------------------------------------------")
#OPTIMIZADO Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
t_cont_prediccion_contra_observación<- xtabs(~Survived+as.factor(prediccionesOptimizadas), data=train2)
print("Tabla de contingencia de predicciones optimizadas peso contra observaciones peso")
t_cont_prediccion_contra_observación
print("----------------------------------------------------------------------------------")
sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
total_elementos <- sum(t_cont_prediccion_contra_observación)
# obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
print("----------------------------------------------------------------------------------")

matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
acierto_tortal <-
  (t_cont_prediccion_contra_observación[1, 1] + t_cont_prediccion_contra_observación[2, 2]) /
  total_elementos
print(paste("Porcentaje de acierto general del modelo: ",acierto_tortal))
print("Matriz de porcentage de aciertos del modelo optimizado")
kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo optimizado. acierto global:",acierto_tortal))%>%
kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
add_header_above(c(" ", "(Prediccion peso)" = 2," "), bold = T, italic = T)%>%
pack_rows("(Observacioens peso)", 1, 2)

#vif para estudial problemas de multicolinearidad si el valor absoluto es > 4 puede haber problemas
print("variance inflation factors")
vif(mymod3)

#vamos a probar el likelihood ratio (LR), or chi-square. como se interpreta??, es de independencia??
loglikelihod<-logLik(mymod3)
print("loglikelihod modelo")
loglikelihod
# este test de likelihod ratio 
# LR = [-2 Log Likelihood (of beginning model)] - [-2 Log Likelihood (of ending model)]. 
likelihoodRatio<-lrtest(mymod3)
likelihoodRatio
model_null = glm(y~1, binomial) #creamos una modelo solo con la constante para comparar el LR, parece que lo hace ya de serie si no se pasan 2 modelos
likelihoodRatio<-lrtest(model_null,mymod3)
print("loglikelihod Ratio test contra modelo con solo la constante")
likelihoodRatio
#Akaike Information Criterion (AIC) tiene relacion con log-likelihood1

#McFadden's-R² es un "Pseudo R²" (sometimes called the likelihood ratio index [LRI]) McFadden =  1 - [-2LL(a,B)/-2LL(a)] 
#funciona como R²: 0 no hay relacion y 1 ajuste perfecto
mcfaddens<-1-logLik(mymod3)/logLik(model_null)
print("MacFadden's Pseudo R²")
mcfaddens

#Wald test - Testing the hypothesis that a coefficient on an independent variable is significantly different from zero
waldtest(model_null,mymod3, test = "Chisq")

#Concordance
#Ideally, the model-calculated-probability-scores of all actual Positive’s, (aka Ones) should be greater than the model-calculated-probability-scores of ALL the Negatives (aka Zeroes). Such a model is said to be perfectly concordant and a highly reliable one. This phenomenon can be measured by Concordance and Discordance.
#In simpler words, of all combinations of 1-0 pairs (actuals), Concordance is the percentage of pairs, whose scores of actual positive’s are greater than the scores of actual negative’s. For a perfect model, this will be 100%. So, the higher the concordance, the better is the quality of model.
concordance(train2$Survived ~ predicciones)

#Specificity and Sensitivity (ya lo calculamos en el porcentage de acierto, para la matriz aciertos!!)
#Sensitivity (or True Positive Rate) is the percentage of 1’s (actuals) correctly predicted by the model, while, specificity is the percentage of 0’s (actuals) correctly predicted. Specificity can also be calculated as 1-False Positive Rate.
print('Valor de sensitivity con optimal cutoff')
sensitivity(mymod3$y, fitted(mymod3), threshold = optCutOff)
print('Valor de specificity con optimal cutoff')
specificity(mymod3$y, fitted(mymod3), threshold = optCutOff)
print('Valor de sensitivity con 0.5 cutoff')
sensitivity(mymod3$y, fitted(mymod3), threshold = 0.5)
print('Valor de specificity con 0.5 cutoff')
specificity(mymod3$y, fitted(mymod3), threshold = 0.5)

#matriz de confusión 
#library(DAAG)
confMatOrigData<-confusion(train2$Survived,predicciones)
print('Matriz de confusion a partir de los datos originales')
confMatOrigData
print('Matriz de confusion a partir de los valores del modelo')
confMat<-confusion(mymod3$y, fitted(mymod3))
confMat


#Calculo de la OR con la variable continua en el modelo a partir de los coeficientes
print('Odds ratio calculadas a partir de los coeficientes')
exp(coef(mymod3))
#Calculo de los intervalos de ocnfianza con la variable continua en el modelo a partir de los coeficientes
print('Intervalos de confianza a partir de los coeficientes')
#si hay factores con ciertos niveles loquea
#exp(confint(mymod3))
#comprobamos con funcion 
library(questionr)
print('Odds ratio calculadas a partir de una funcion para comprobación')
#si hay factores con ciertos niveles loquea
#odds.ratio(mymod3)

#print('contraste de todos los modelos con anova')
#anova(mymod1, mymod2, mymod3, test="Chisq")


## Predicción
# vlaores_variables_explicativas <- data.frame(x1 = 'S', x2 = 90)
# predict(modelo_para_prediccion2,vlaores_variables_explicativas, type="response")
# vlaores_variables_explicativas2 <- data.frame(x1 ='S', x2 = 90,x3='Barcelona')
# predict(mymod3,vlaores_variables_explicativas2, type="response")

##2.4. Bondad del ajuste
#Usa el test de Hosman-Lemeshow para ver la bondad de ajuste del modelo final escogido. En la librería (ResourceSelection) hay una función que ajusta el test de Hosmer- Lemeshow.
#library(ResourceSelection)
hl<-hoslem.test(mymod3$y,fitted(mymod3))
hl
#This gives p=0.69, indicating no evidence of poor fit. This is good, since here we know the model is indeed correctly specified. We can also obtain a table of observed vs expected, from our hl object:
cbind(hl$observed,hl$expected)

##2.5. Curva ROC
#Dibujar la curva ROC, y calcular el área debajo de la curva.Discutir el resultado.
plotROC(mymod3$y,fitted(mymod3))

```


## Prediccion por varios metodos package caret

```{r pruebas_predict_rf, size="small"}

# Partimos el dataset en los conjuntos iniciales de train y test.
trainCARET <- muestra[1:891,-c(4,9,11,13,14,20)]
testCARET <- muestra[892:1309,]

# #he function createDataPartition can be used to create a stratified random sample of the data into training and test sets:
# #library(caret)
# set.seed(998)
# inTraining <- createDataPartition(trainCARET$Survived, p = .75, list = FALSE)
# trainingCARET <- trainCARET[ inTraining,]
# testingCARET  <- trainCARET[-inTraining,]

trainingMod<-trainCARET
trainingMod$Survived<-as.factor(trainingMod$Survived)
levels(trainingMod$Survived) <- c('No','Si') 
levels(trainingMod$PclassFactor) <- c('Primera','Segunda','Tercera')
trainingMod$LoneWolfs <- ifelse(trainingMod$LoneWolfs, 'Si', 'No')
trainingMod$IsMother <- ifelse(trainingMod$IsMother, 'Si', 'No')
trainingMod$youngTravelAl  <- ifelse(trainingMod$youngTravelAl, 'Si', 'No')
trainingMod$LoneWolfs <- as.factor(trainingMod$LoneWolfs)
trainingMod$IsMother <- as.factor(trainingMod$IsMother)
trainingMod$youngTravelAl  <- as.factor(trainingMod$youngTravelAl)

testMod<-trainCARET
testMod$LoneWolfs <- ifelse(testMod$LoneWolfs, 'Si', 'No')
testMod$IsMother <- ifelse(testMod$IsMother, 'Si', 'No')
testMod$youngTravelAl  <- ifelse(testMod$youngTravelAl, 'Si', 'No')
testMod$LoneWolfs <- as.factor(testMod$LoneWolfs)
testMod$IsMother <- as.factor(testMod$IsMother)
testMod$youngTravelAl  <- as.factor(testMod$youngTravelAl)

#creamos un conjunto de entrenamiento y test propios a partir de train para calcular nuestros porcentaje de acierto
## 85% of the sample size
smp_size <- floor(0.85 * nrow(trainingMod))
## Establecemos una semilla para poder volver a reproducir el mismo muestreo
set.seed(123)
train_ind <- sample(seq_len(nrow(trainingMod)), size = smp_size)
training <- trainingMod[train_ind, ]
testing <- trainingMod[-train_ind, ]
test3Survival<-testing$Survived
testing$Survived <- NA

train_control <- trainControl(method = 'cv', number = 10, classProbs = TRUE, summaryFunction = twoClassSummary)

# #Basic Linear Modelling

logRegModel <- caret::train(Survived ~ ., data = training, trControl = train_control,
                     method = 'glm', family = binomial(),
                     metric = 'ROC')
# cross validation results
print(logRegModel)
coef(summary(logRegModel))


#Naive Bayes
nbModel <- caret::train(Survived ~ ., data = training, trControl = train_control,
                 method = 'nb', tuneLength = 10,
                 metric = 'ROC')

#Random Forest - Variable Importance
rfModel <- caret::train(Survived ~ ., data = training, trControl = train_control,
                 method = 'rf', tuneLength = 10,
                 metric = 'ROC')
varImp(rfModel)

#Neural Networks
nnGrid <- expand.grid(.size = c(1,2,3,4,5,6,7),
                      .decay = c(0, .01, .1, .2, .3, .4, .5, 1, 2))

nnModel <- caret::train(Survived ~ ., data = training, trControl = train_control,
                 method = 'nnet', tuneGrid = nnGrid,
                 metric = 'ROC', trace = FALSE)

pcaNNModel <- train(Survived ~ ., data = training, trControl = train_control,
                 method = 'pcaNNet', tuneGrid = nnGrid,
                 metric = 'ROC', trace = FALSE)



# #Vamos a comparar el resultado con las observaciones de la variable y construir una matriz de acierto
# t_cont_prediccion_contra_observación<- xtabs(~test4Survival+submittest3cf$Survived)
# print("Tabla de contingencia de predicciones survival contra observaciones survival")
# t_cont_prediccion_contra_observación
# sumatorios_filas <- rowSums(t_cont_prediccion_contra_observación)
# sumatorios_columnas <- colSums(t_cont_prediccion_contra_observación)
# total_elementos <- sum(t_cont_prediccion_contra_observación)
# # obtenemos los porcentages de aciertos de 1s(Sensitivity) y 0s(specificity)
# porcentaje_de_acierto <- t_cont_prediccion_contra_observación[,1]/sumatorios_filas
# porcentaje_de_acierto[2]<-1-porcentaje_de_acierto[2] 
# porcentaje_de_acierto
# print("Matriz de porcentage de aciertos del modelo")
# matriz_aciertos<-cbind(t_cont_prediccion_contra_observación,porcentaje_de_acierto)
# print("acierto general del modelo")
# acierto_tortal <-  (t_cont_prediccion_contra_observación[1,1]+t_cont_prediccion_contra_observación[2,2])/total_elementos
# acierto_tortal
# kable(matriz_aciertos, caption = paste("Matriz de acierto del modelo. acierto global:",acierto_tortal))%>%
# kable_styling(latex_options = c("striped", "hold_position"), position = "center", font_size = 8)%>%
# add_header_above(c(" ", "(Prediccion survival)" = 2," "), bold = T, italic = T)%>%
# pack_rows("(Observacioens survival)", 1, 2)


```
